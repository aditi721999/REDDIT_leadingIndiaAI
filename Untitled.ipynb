{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(93504, 5)\n"
     ]
    }
   ],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "import re\n",
    "import pandas as pd\n",
    "import nltk\n",
    "from wordcloud import WordCloud\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "#import data of reddit/sports \n",
    "data = pd.read_csv('reddit.csv')\n",
    "\n",
    "# check shape of dataframes\n",
    "print(data.shape)\n",
    "\n",
    "\n",
    "\n",
    "def sub_preprocess(sub):\n",
    "   \n",
    "    # run regex to remove certain characters\n",
    "    sub['Title'] = sub['Title'].map(lambda x: re.sub(r\"[@\\?\\.$%_\\[\\]()+-:*\\\"]\", ' ', x, flags=re.I))\n",
    "    sub['Title'] = sub['Title'].map(lambda x: re.sub(r\"[,']\", '', x, flags=re.I))\n",
    "    sub['Title'] = sub['Title'].map(lambda x: re.sub(\"(?<![\\w'])\\w+?(?=\\b|'s)\", ' ', x))\n",
    "\n",
    " \n",
    "sub_preprocess(data)\n",
    "\n",
    "\n",
    "#storing stopwords\n",
    "stopwords = nltk.corpus.stopwords.words('english')\n",
    "\n",
    "\n",
    "#function to give wordcloud image of words used in text column\n",
    "def cloud(df):\n",
    "\n",
    "    t = ' '\n",
    "# iterate through the csv file \n",
    "    for x in df['Title']: \n",
    "          \n",
    "        # typecaste each val to string \n",
    "        x = str(x) \n",
    "      \n",
    "        # split the value \n",
    "        values = x.split() \n",
    "          \n",
    "        # Converts each token into lowercase \n",
    "        for i in range(len(values)): \n",
    "            values[i] = values[i].lower() \n",
    "              \n",
    "        for words in values: \n",
    "            t = t + words + ' '\n",
    "      \n",
    "  \n",
    "    wc = WordCloud(max_words= 100,\n",
    "                      width = 744, \n",
    "                      height = 544,\n",
    "                      background_color ='white',\n",
    "                      stopwords=stopwords, \n",
    "                      contour_width=3, \n",
    "                      contour_color='steelblue',\n",
    "                      min_font_size = 10).generate(t) \n",
    "  \n",
    "    # plot the WordCloud image                        \n",
    "    plt.figure(figsize = (10, 10)) \n",
    "    plt.imshow(wc) \n",
    "    plt.axis(\"off\")\n",
    "    plt.savefig('reddit_title.png')\n",
    "\n",
    "cloud(data)\n",
    "\n",
    "\n",
    "#tokenization ,stopwords removal and stemmization\n",
    "tokenized_tweet = data['text'].apply(lambda x: x.split())\n",
    "tokenized_tweet.head()\n",
    "tokenized_tweet = tokenized_tweet.apply(lambda x: [w for w in x if w not in stopwords])\n",
    "from nltk.stem.porter import *\n",
    "stemmer = PorterStemmer()\n",
    "tokenized_tweet = tokenized_tweet.apply(lambda x: [stemmer.stem(i) for i in x]) # stemming\n",
    "tokenized_tweet.head()\n",
    "for i in range(len(tokenized_tweet)):\n",
    "    tokenized_tweet[i] = ' '.join(tokenized_tweet[i])\n",
    "#Text_pp - column after stopwords removal and stemming\n",
    "data['text_pp'] = tokenized_tweet"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def cloud(df):\n",
    "\n",
    "    t = ' '\n",
    "# iterate through the csv file \n",
    "    for x in df['Title']: \n",
    "          \n",
    "        # typecaste each val to string \n",
    "        x = str(x) \n",
    "      \n",
    "        # split the value \n",
    "        values = x.split() \n",
    "          \n",
    "        # Converts each token into lowercase \n",
    "        for i in range(len(values)): \n",
    "            values[i] = values[i].lower() \n",
    "              \n",
    "        for words in values: \n",
    "            t = t + words + ' '\n",
    "      \n",
    "  \n",
    "    wc = WordCloud(max_words= 100,\n",
    "                      width = 744, \n",
    "                      height = 544,\n",
    "                      background_color ='white',\n",
    "                      stopwords=stopwords, \n",
    "                      contour_width=3, \n",
    "                      contour_color='steelblue',\n",
    "                      min_font_size = 10).generate(t) \n",
    "  \n",
    "    # plot the WordCloud image                        \n",
    "    plt.figure(figsize = (10, 10)) \n",
    "    plt.imshow(wc) \n",
    "    plt.axis(\"off\")\n",
    "    plt.savefig('reddit_title.png')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "cloud(data)\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
